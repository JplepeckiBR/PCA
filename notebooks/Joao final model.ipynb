{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-02 09:59:04.413636: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-02 09:59:04.423896: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-02 09:59:04.504461: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-02 09:59:04.587218: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-02 09:59:04.653537: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-02 09:59:04.671482: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-02 09:59:04.800460: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-02 09:59:05.883199: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from tensorflow.keras.utils import load_img\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paths to files\n",
    "image_dir = \"../raw_data/facial_segmentation/image/\"\n",
    "mask_dir = \"../raw_data/facial_segmentation/masks/seg/\"\n",
    "\n",
    "#variables that hold file names\n",
    "image_filenames = os.listdir(image_dir)\n",
    "mask_filenames = os.listdir(mask_dir)\n",
    "\n",
    "#sorting file names\n",
    "image_filenames.sort()\n",
    "mask_filenames.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_of_file = 5000\n",
    "# training on size of file number of images training\n",
    "image_filenames = image_filenames[:size_of_file]\n",
    "mask_filenames = mask_filenames[:size_of_file]\n",
    "\n",
    "IMG_SIZE = (256, 256)\n",
    "\n",
    "images = []\n",
    "masks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to check if a path is a file\n",
    "def is_file(path):\n",
    "    return os.path.isfile(path)\n",
    "\n",
    "# Loop through each pair of image and mask filenames\n",
    "for image_filename, mask_filename in zip(image_filenames, mask_filenames):\n",
    "    # Construct full file paths\n",
    "    image_path = os.path.join(image_dir, image_filename)\n",
    "    mask_path = os.path.join(mask_dir, mask_filename)\n",
    "\n",
    "    # Check if files exist and are files\n",
    "    if not is_file(image_path):\n",
    "        continue\n",
    "    if not is_file(mask_path):\n",
    "        continue\n",
    "\n",
    "    # Load and preprocess the face image\n",
    "    img = load_img(image_path, target_size=IMG_SIZE)\n",
    "    img = img_to_array(img) / 255.0  # Normalize to [0, 1]\n",
    "\n",
    "    # Load and preprocess the mask\n",
    "    mask = load_img(mask_path, target_size=IMG_SIZE, color_mode=\"grayscale\")\n",
    "    mask = img_to_array(mask)  # Normalize to [0, 1]\n",
    "\n",
    "    # Append the processed image and mask to the respective lists\n",
    "    images.append(img)\n",
    "    masks.append(mask)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "images = np.array(images)\n",
    "masks = np.array(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (4000, 256, 256, 3), Training masks shape: (4000, 256, 256, 1)\n",
      "Test data shape: (1000, 256, 256, 3), Test masks shape: (1000, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "# Split into training and validation sn, y_test = train_test_split(images, masksets (80% training, 20% validation)\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, masks, test_size=0.2, random_state=42)\n",
    "# Print shapes to confirm the split\n",
    "print(f\"Training data shape: {X_train.shape}, Training masks shape: {y_train.shape}\")\n",
    "print(f\"Test data shape: {X_test.shape}, Test masks shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define valid values to keep\n",
    "valid_values = {1, 2, 3, 4, 5, 7, 9, 10}\n",
    "\n",
    "y_train = np.where(np.isin(y_train, list(valid_values)), y_train, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "label_mapping = {1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 7: 6, 9: 7, 10: 8}\n",
    "\n",
    "# Apply the mapping\n",
    "for old_value, new_value in label_mapping.items():\n",
    "    y_train[y_train == old_value] = new_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train,num_classes = 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def conv_block(inputs, num_filters):\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def encoder_block(inputs, num_filters):\n",
    "    x = conv_block(inputs, num_filters)\n",
    "    p = MaxPool2D((2, 2))(x)\n",
    "    return x, p\n",
    "\n",
    "def decoder_block(inputs, skip, num_filters):\n",
    "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(inputs)\n",
    "    x = Concatenate()([x, skip])\n",
    "    x = conv_block(x, num_filters)\n",
    "    return x\n",
    "\n",
    "def build_unet(input_shape, num_classes):\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    s1, p1 = encoder_block(inputs, 64)\n",
    "    s2, p2 = encoder_block(p1, 128)\n",
    "    s3, p3 = encoder_block(p2, 256)\n",
    "    s4, p4 = encoder_block(p3, 512)\n",
    "\n",
    "    b1 = conv_block(p4, 1024)\n",
    "\n",
    "    d1 = decoder_block(b1, s4, 512)\n",
    "    d2 = decoder_block(d1, s3, 256)\n",
    "    d3 = decoder_block(d2, s2, 128)\n",
    "    d4 = decoder_block(d3, s1, 64)\n",
    "\n",
    "    outputs = Conv2D(num_classes, 1, padding=\"same\", activation=\"softmax\")(d4)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_shape = (256, 256, 3)\n",
    "    model = build_unet(input_shape, 9)\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPooling2D, UpSampling2D, Concatenate, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('unet_model2.h5', save_best_only=True)\n",
    "early_stopping = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size = 16, callbacks=[checkpoint, early_stopping], validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "predicted_mask = model.predict(np.expand_dims(X_train[0], axis=0))\n",
    "\n",
    "print(predicted_mask.shape)\n",
    "# Assuming one-hot encoded mask with 9 classes\n",
    "predicted_mask = np.argmax(predicted_mask, axis=-1)  # Select channel with highest probability\n",
    "predicted_mask = np.reshape(predicted_mask, (256, 256))\n",
    "plt.imshow(predicted_mask, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PCA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
